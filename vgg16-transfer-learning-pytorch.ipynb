{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "26359bdf-00a9-4280-9ec4-6ca7295148e4",
    "_uuid": "108609d6b29e75ec9f0fe15f66b4336f694c74b2"
   },
   "source": [
    "## VGG implementation with SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b4eb5ad5-03ba-4fc4-b417-451e30a01fd1",
    "_uuid": "be3002e45fc687fc33e7c7ae9d869ac7ee926b1a"
   },
   "source": [
    "*Python Modules*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n",
    "A lot of work here is derivative. Multiple sources have been referred to come up with the architecture and the solution given here though the task as a whole has not been directly used. I will make an effort to refer to the sources these to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "0e05b5f8-fc51-404d-a9d2-5197aa283b73",
    "_uuid": "76fd0ec2a5eb7fbe49b51147eabbd109c61279c0",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import sklearn.svm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "plt.ion() \n",
    "\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader functions\n",
    "ImageFolder loads the data directly from its path. transforms are used to then compose the same into the size needed for vggnet and alexnet. The data is then loaded based on the input size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "e9d7ef88-fdbd-4b73-b64f-70294976d238",
    "_uuid": "83371f19c7f1e261bb0f9cc71f7a265c37a4c16a",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 1074,
     "status": "ok",
     "timestamp": 1525007461873,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "xvsy0IR4wheJ",
    "outputId": "bb02efaa-518c-4342-d6e5-7275a7d7fdd5"
   },
   "outputs": [],
   "source": [
    "def data_loader(log,data_dir, TRAIN, TEST,  image_crop_size = 224, mini_batch_size = 1 ):\n",
    "    # VGG-16 Takes 224x224 images as input, so we resize all of them\n",
    "    data_transforms = {\n",
    "        TRAIN: transforms.Compose([\n",
    "            # Data augmentation is a good practice for the train set\n",
    "            # Here, we randomly crop the image to 224x224 and\n",
    "            # randomly flip it horizontally. \n",
    "            transforms.RandomResizedCrop(224),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "        ]),\n",
    "        TEST: transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    image_datasets = {\n",
    "        x: datasets.ImageFolder(\n",
    "            os.path.join(data_dir, x), \n",
    "            transform=data_transforms[x]\n",
    "        )\n",
    "        for x in [TRAIN, TEST]\n",
    "    }\n",
    "\n",
    "    dataloaders = {\n",
    "        x: torch.utils.data.DataLoader(\n",
    "            image_datasets[x], batch_size=1,\n",
    "            shuffle=True, num_workers=1\n",
    "        )\n",
    "        for x in [TRAIN, TEST]\n",
    "    }\n",
    "    print(\"Data loading complete\")\n",
    "    return dataloaders, image_datasets\n",
    "    \n",
    "def update_details(log, image_datasets):\n",
    "    dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, TEST]}\n",
    "\n",
    "    for x in [TRAIN, TEST]:\n",
    "        print(\"Loaded {} images under {}\".format(dataset_sizes[x], x), file = log)\n",
    "\n",
    "    print(\"Classes: \", file = log)\n",
    "    class_names = image_datasets[TRAIN].classes\n",
    "    classification_size = len(image_datasets[TRAIN].classes)\n",
    "    print(image_datasets[TRAIN].classes)\n",
    "    print(classification_size)\n",
    "    \n",
    "    return dataset_sizes, classification_size, class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ad1e66d-dcfc-429a-9664-e61b4d2944cc",
    "_uuid": "80417b6d4f2000be40245a090424b2452e1b78e1",
    "colab_type": "text",
    "id": "6f1fb14iwheO"
   },
   "source": [
    "## Setting up the network\n",
    "\n",
    "Some utility function to visualize the dataset and the model's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "4be764f7-24ff-4611-8fc6-31b87e3ed171",
    "_uuid": "480b7181f00142865d3e971c799dd42bc9d1f7e5",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 1003
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2623,
     "status": "ok",
     "timestamp": 1525007474565,
     "user": {
      "displayName": "Carlo Alberto",
      "photoUrl": "//lh5.googleusercontent.com/-_sBZsyc315U/AAAAAAAAAAI/AAAAAAAAAgg/b4D9SE9jgD0/s50-c-k-no/photo.jpg",
      "userId": "107843268563316278814"
     },
     "user_tz": -120
    },
    "id": "SjHLMTldwheY",
    "outputId": "4c40caae-9d25-47e5-fe17-a4f3f944487e"
   },
   "outputs": [],
   "source": [
    "def set_up_network(net, freeze_training = True, clip_classifier = True, classification_size = 101):\n",
    "    if net == 'vgg16':\n",
    "    # Load the pretrained model from pytorch\n",
    "        network = models.vgg16(pretrained=True)\n",
    "\n",
    "        # Freeze training for all layers\n",
    "        # Newly created modules have require_grad=True by default\n",
    "        if freeze_training:\n",
    "            for param in network.features.parameters():\n",
    "                param.require_grad = False\n",
    "\n",
    "        if clip_classifier:\n",
    "            features = list(network.classifier.children())[:-5] # Remove last layer\n",
    "            network.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "    \n",
    "    elif net == 'alexnet':\n",
    "        network = models.alexnet(pretrained=True)\n",
    "        if freeze_training:\n",
    "            for param in network.features.parameters():\n",
    "                param.require_grad = False\n",
    "        \n",
    "        if clip_classifier:\n",
    "            features = list(network.classifier.children())[:-4] # Remove last layer\n",
    "            network.classifier = nn.Sequential(*features) # Replace the model classifier\n",
    "    if classification_size != 1000 and clip_classifier == False:\n",
    "        num_features = network.classifier[6].in_features\n",
    "        features = list(network.classifier.children())[:-1] # Remove last layer\n",
    "        features.extend([nn.Linear(num_features, classification_size)]) # Add our layer with 4 outputs\n",
    "        network.classifier = nn.Sequential(*features) # Replace the model cla\n",
    "#     print(network)\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Update Features\n",
    "This function updates the network output for then being able to update it for SVM layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features( log, ipnet, train_batches = 10, number_of_classes = 10 ):\n",
    "\n",
    "    imgfeatures = []\n",
    "    imglabels = []\n",
    "    if classification_size < number_of_classes:\n",
    "        number_of_classes = classification_size\n",
    "        print(\"Input size smaller at:\", classification_size,\". Adjusting the class to this number\", file = log)\n",
    "    selected_classes = random.sample(range(0,classification_size), number_of_classes)\n",
    "    print(\"The selected classes are: \",selected_classes, file = log)\n",
    "    for i, data in enumerate(dataloaders[TRAIN]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTraining batch {}/{}\".format(i, train_batches), file=log)\n",
    "            print(\"\\r Getting features of {}/{}\".format(i, train_batches), end='')\n",
    "\n",
    "        # Use half training dataset\n",
    "        if i > train_batches:\n",
    "            break\n",
    "\n",
    "        inputs, labels = data\n",
    "        if(labels.numpy() not in selected_classes): \n",
    "            continue\n",
    "        \n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        feature = ipnet(inputs)\n",
    "#         print(\"The shape of output is: \", feature.shape)\n",
    "#         print(labels)\n",
    "        if use_gpu:\n",
    "            imgfeatures.append(feature.cpu().detach().numpy().flatten())\n",
    "            imglabels.append(labels.cpu().detach().numpy())\n",
    "        else:\n",
    "            imgfeatures.append(feature.detach().numpy().flatten())\n",
    "            imglabels.append(labels.detach().numpy())\n",
    "        del inputs, labels, feature\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Features Updated\")\n",
    "    return imgfeatures, imglabels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit features to SVM and predict output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_features_to_SVM(log, class_names, features, labels, train_batch_size,  K=5  ):\n",
    "\n",
    "    kf = sklearn.model_selection.KFold(n_splits=K)\n",
    "    kf.get_n_splits(features)\n",
    "    scores = []\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "#     print(features.shape)\n",
    "#     print(labels.shape)\n",
    "\n",
    "    i=0\n",
    "    for train, test in kf.split(features):\n",
    "        i+=1\n",
    "        model = sklearn.svm.SVC(C=1.0, kernel='linear') #, C=1, gamma=0)\n",
    "        model.fit(features[train, :], labels[train].ravel())\n",
    "        out_predict = model.predict(features[test, :])\n",
    "        \n",
    "        y_label = labels[test].ravel()\n",
    "        print(\"Confusion Matrix\", file=log)\n",
    "        print(confusion_matrix(y_label, out_predict), file=log)  \n",
    "        print(\"-\"*30, file=log)\n",
    "#         print(\"Classification Report\")\n",
    "#         print(classification_report(y_label,out_predict))\n",
    "        \n",
    "        print(\"List of classification Accuracy\", file=log)\n",
    "        data = Counter(y_label[y_label==out_predict])\n",
    "        stat = data.most_common()\n",
    "        stat = np.array(stat)\n",
    "        print(stat, file=log)   # Returns all unique items and their counts\n",
    "        \n",
    "        print(\" The best classification accuracy is: \", stat[0,1]/np.sum(y_label[y_label==stat[0,1]]), file=log)\n",
    "        print(\" The worst classification accuracy is: \", stat[-1,1]/np.sum(y_label[y_label==stat[-1,1]]), file=log)\n",
    "        \n",
    "        s=model.score(features[test, :], labels[test])\n",
    "        print(i,\"/\",K,\"The score for this classification is: \", s, file = log)\n",
    "        scores.append(s)\n",
    "        break\n",
    "    return np.mean(scores), np.std(scores)\n",
    "\n",
    "# This is an alternative implementation using the same thing.\n",
    "def fit_features_to_SVM_new( log,features, labels, train_batch_size, K=5  ):\n",
    "    features = np.array(features)\n",
    "    labels = np.array(labels)\n",
    "    scores = []\n",
    "    for i in range(K):\n",
    "        x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=(1/K), random_state=42)\n",
    "        model = sklearn.svm.SVC(C=100)#, C=1, gamma=0)\n",
    "        model.fit(x_train, y_train.ravel())\n",
    "        s=model.score(x_test, y_test)\n",
    "        print(\"The score for this classification is: \", s, file = log)\n",
    "        scores.append(s)\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This part is common for both VGG and Alexnet\n",
    "# data_dir_10 = \"/home/student/meowth/imgClas/food/class10\"  \n",
    "# data_dir_30 = \"/home/student/meowth/imgClas/food/class30\"\n",
    "data_dir_10 = \"C:\\DeepLearning\\images\\class10\"  \n",
    "data_dir_30 = \"C:\\DeepLearning\\images\\class10\"\n",
    "# ImageDirectory = [data_dir_10, data_dir_30]\n",
    "ImageDirectory = [data_dir_10]\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 implementation with SVM as a classification layer. (All Updates here)\n",
    "This updates the data, sets up the network and classifies using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete\n",
      "['beef_tartare', 'caesar_salad', 'chocolate_cake', 'croque_madame', 'escargots', 'fried_calamari', 'macaroni_and_cheese', 'poutine', 'spring_rolls', 'tuna_tartare']\n",
      "10\n",
      "Getting features\n",
      " Getting features of 0/50Features Updated\n",
      "Fitting features to svm\n",
      " The best classification accuracy is:  1.0\n",
      " The best classification accuracy is:  1.0\n"
     ]
    }
   ],
   "source": [
    "# # Set up the network\n",
    "# vgg16_nc = set_up_network('vgg16', freeze_training = True)\n",
    "# if use_gpu:\n",
    "#     vgg16_nc.cuda() #.cuda() will move everything to the GPU side\n",
    "\n",
    "# for i, data_dir in enumerate(ImageDirectory):\n",
    "#     file = open(\"VGG16_Task1\"+str(i)+\".txt\", \"w\")\n",
    "\n",
    "#     # Get Data\n",
    "#     dataloaders, image_datasets = data_loader(file,data_dir, TRAIN, TEST, \n",
    "#                                               image_crop_size = 224, mini_batch_size = 1 )\n",
    "#     dataset_sizes, classification_size, class_names = update_details(file, image_datasets)\n",
    "    \n",
    "#     # Update train_batch_size\n",
    "#     train_batch_size = dataset_sizes[TRAIN]\n",
    "#     train_batch_size = 50\n",
    "#     class_size = classification_size\n",
    "    \n",
    "#     # Get the image features for the imagenet trained network.\n",
    "#     print(\"Getting features\")\n",
    "#     imgfeatures_vgg, imglabels_vgg = get_features(file, vgg16_nc, train_batch_size,\n",
    "#                                                   number_of_classes = class_size)\n",
    "#     print(\"Fitting features to svm\")\n",
    "#     mean_accuracy, sd = fit_features_to_SVM(file, class_names, imgfeatures_vgg,\n",
    "#                                         imglabels_vgg, train_batch_size, K=5)\n",
    "    \n",
    "#     print(\"The mean and standard deviation of classification for vgg 16 is: \",\n",
    "#       mean_accuracy, sd, \"for class size: \", class_size, file = file)\n",
    "#     del dataloaders, image_datasets, imgfeatures_vgg, imglabels_vgg\n",
    "#     file.close()\n",
    "# del vgg16_nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alexnet implementation with SVM as a classification layer. \n",
    "The batch size and other things can be classified from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "f8d905fe-9f7f-484b-b926-9931ca887e34",
    "_uuid": "2803b24b7002a785833d300413e3bd8891f398f9",
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete\n",
      "['beef_tartare', 'caesar_salad', 'chocolate_cake', 'croque_madame', 'escargots', 'fried_calamari', 'macaroni_and_cheese', 'poutine', 'spring_rolls', 'tuna_tartare']\n",
      "10\n",
      " Getting features of 100/100Features Updated\n",
      " The best classification accuracy is:  0.3333333333333333\n",
      " The best classification accuracy is:  0.25\n"
     ]
    }
   ],
   "source": [
    "# # Set up the network\n",
    "# alex_net_nc = set_up_network('alexnet', freeze_training = True)\n",
    "# if use_gpu:\n",
    "#     alex_net_nc.cuda() #.cuda() will move everything to the GPU side\n",
    "\n",
    "# for i, data_dir in enumerate(ImageDirectory):\n",
    "#     file = open(\"AlexNet_Task1\"+str(i)+\".txt\", \"w\")\n",
    "    \n",
    "#     # Get Data\n",
    "#     dataloaders, image_datasets = data_loader(file, data_dir, TRAIN, TEST, \n",
    "#                                               image_crop_size = 224, mini_batch_size = 1)\n",
    "#     dataset_sizes, classification_size, class_names = update_details(file, image_datasets)\n",
    "    \n",
    "#     # Update train_batch_size\n",
    "#     train_batch_size = dataset_sizes[TRAIN]\n",
    "#     train_batch_size = 100\n",
    "#     class_size = classification_size\n",
    "    \n",
    "#     # Get the image features for the imagenet trained network.\n",
    "#     imgfeatures_alexn, imglabels_alexn = get_features(file, alex_net_nc, train_batch_size,\n",
    "#                                                       number_of_classes = class_size)\n",
    "#     mean_accuracy, sd = fit_features_to_SVM(file, class_names, imgfeatures_alexn,\n",
    "#                                         imglabels_alexn, train_batch_size, K=5)\n",
    "#     print(\"The mean and standard deviation of classification for AlexNet is: \",\n",
    "#       mean_accuracy, sd, \"for class size: \", class_size, file = file)\n",
    "#     del dataloaders, image_datasets, imgfeatures_alexn, imglabels_alexn\n",
    "#     file.close()\n",
    "# del alex_net_nc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: This one trains on top of the existing pre-trained network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "Here, based on whether label smoothing is needed or not, a different loss function is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(pred, gold, smoothing = False):\n",
    "    ''' Calculate cross entropy loss, apply label smoothing if needed. '''\n",
    "\n",
    "    gold = gold.contiguous().view(-1)\n",
    "\n",
    "    if smoothing:\n",
    "        eps = 0.1\n",
    "        n_class = pred.size(1)\n",
    "\n",
    "        one_hot = torch.zeros_like(pred).scatter(1, gold.view(-1, 1), 1)\n",
    "        one_hot = one_hot * (1 - eps) + (1 - one_hot) * eps / (n_class - 1)\n",
    "        log_prb = F.log_softmax(pred, dim=1)\n",
    "\n",
    "        non_pad_mask = gold.ne(0)\n",
    "        loss = -(one_hot * log_prb).sum(dim=1)\n",
    "        loss = loss.masked_select(non_pad_mask).sum()  # average later\n",
    "    else:\n",
    "        loss = nn.CrossEntropyLoss()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dabed264-9a90-4888-ad3c-65924ad9c80d",
    "_uuid": "eff4aa2d97fd5443195ae2a2cd43c5f73e6775a3"
   },
   "source": [
    "## Training with cross-validation.\n",
    "Here, a split of 80% for training and 20% for validation is done for cross validation. It otherwise follows the standard training example given in pytorch site.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "_cell_guid": "8f6936eb-ae6f-44ee-90a9-c7f817ba6eda",
    "_uuid": "abe5dc35b31e7971e7d63637866132f89e7d011d",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "lHkiBU5fwhet"
   },
   "outputs": [],
   "source": [
    "def train_model(log, vgg, criterion, optimizer, scheduler, dataloaders, num_epochs=10, label_smoothing = False):\n",
    "    since = time.time()\n",
    "    best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    avg_loss_val = 0\n",
    "    avg_acc_val = 0\n",
    "    K = 5\n",
    "    train_batches = len(dataloaders[TRAIN])\n",
    "    train_bat = np.ones((train_batches, 1)) # This is a dummy variable as sklearn changed stuff and didn't do it right.\n",
    "    val_batches = 0.2*train_batches\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs), file=log)\n",
    "        print(\"Epoch {}/{}\".format(epoch, num_epochs), end='')\n",
    "        print('-' * 10)\n",
    "        \n",
    "        loss_train = 0\n",
    "        loss_val = 0\n",
    "        acc_train = 0\n",
    "        acc_val = 0\n",
    "        \n",
    "        vgg.train(True)\n",
    "       \n",
    "        kf = sklearn.model_selection.KFold(n_splits=K)\n",
    "        kf.get_n_splits(train_bat)\n",
    "        \n",
    "        run_count = 0\n",
    "        for train, test in kf.split(train_bat):\n",
    "\n",
    "            if run_count > 0:\n",
    "                break\n",
    "#             run_count = 1 # If commented skips cross validation\n",
    "            \n",
    "            for i, data in enumerate(dataloaders[TRAIN]):\n",
    "                if i % 100 == 0:\n",
    "                    print(\"\\rTraining batch {}/{}\".format(i, train_batches / 2), end='')\n",
    "\n",
    "                # Use half training dataset\n",
    "                if i >= train_batches:\n",
    "#                 if i >= 1:\n",
    "                    break\n",
    "                \n",
    "                if i not in train:\n",
    "                    continue\n",
    "                \n",
    "                inputs, labels = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "#                 loss_train += loss.item()\n",
    "                loss_train += loss.data[0]\n",
    "                acc_train += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "            print()\n",
    "            # * 2 as we only used half of the dataset\n",
    "            avg_loss = loss_train * 2 / (dataset_sizes[TRAIN]*0.8)\n",
    "            avg_acc = acc_train * 2 / (dataset_sizes[TRAIN]*0.8)\n",
    "\n",
    "            vgg.train(False)\n",
    "            vgg.eval()\n",
    "\n",
    "            for i, data in enumerate(dataloaders[TRAIN]):\n",
    "                if i % 5000 == 0:\n",
    "                    print(\"\\rValidation batch {}/{}\".format(i, val_batches), file=log)\n",
    "\n",
    "#                 if i >= 1:\n",
    "#                     break\n",
    "                if i not in test:\n",
    "                    continue\n",
    "                \n",
    "                inputs, labels = data\n",
    "                \n",
    "                if use_gpu:\n",
    "                    inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "                else:\n",
    "                    inputs, labels = Variable(inputs, requires_grad=True), Variable(labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                outputs = vgg(inputs)\n",
    "\n",
    "                _, preds = torch.max(outputs.data, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                loss_val += loss.data[0]\n",
    "#                 loss_train += loss.item()\n",
    "                acc_val += torch.sum(preds == labels.data)\n",
    "\n",
    "                del inputs, labels, outputs, preds\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            avg_loss_val = loss_val / (dataset_sizes[TRAIN]*0.2)\n",
    "            avg_acc_val = acc_val / (dataset_sizes[TRAIN]*0.2)\n",
    "\n",
    "            print( file = log)\n",
    "            print(\"Epoch {} result: \".format(epoch), file = log)\n",
    "            print(\"Avg loss (train): {:.4f}\".format(avg_loss), file = log)\n",
    "            print(\"Avg acc (train): {:.4f}\".format(avg_acc), file = log)\n",
    "            print(\"Avg loss (val): {:.4f}\".format(avg_loss_val), file = log)\n",
    "            print(\"Avg acc (val): {:.4f}\".format(avg_acc_val), file = log)\n",
    "            print('-' * 10)\n",
    "            print()\n",
    "\n",
    "            if avg_acc_val > best_acc:\n",
    "                best_acc = avg_acc_val\n",
    "                best_model_wts = copy.deepcopy(vgg.state_dict())\n",
    "        \n",
    "    elapsed_time = time.time() - since\n",
    "    print(file = log)\n",
    "    print(\"Training completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60), file = log)\n",
    "    print(\"Best acc: {:.4f}\".format(best_acc), file = log)\n",
    "    \n",
    "    vgg.load_state_dict(best_model_wts)\n",
    "    return vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model\n",
    "In this step, images from validation is chosen and is used for evaluating the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "_cell_guid": "1b74302a-9418-4472-970f-76591d00cecb",
    "_uuid": "6d1b1cd49e177152940d8f667b9fa5e2e1c5e360",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_model(log, vgg, criterion, label_smoothing = False):\n",
    "    since = time.time()\n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "    loss_test = 0\n",
    "    acc_test = 0\n",
    "    \n",
    "    test_batches = len(dataloaders[TEST])\n",
    "    print(\"Evaluating model\")\n",
    "    print('-' * 10)\n",
    "    labels_pred = []\n",
    "    labels_expected = []\n",
    "    labels_pred = np.array(labels_pred)\n",
    "    labels_expected = np.array(labels_expected)\n",
    "    for i, data in enumerate(dataloaders[TEST]):\n",
    "        if i % 100 == 0:\n",
    "            print(\"\\rTest batch {}/{}\".format(i, test_batches), file=log)\n",
    "#         if i >= 50:\n",
    "#             break\n",
    "        vgg.train(False)\n",
    "        vgg.eval()\n",
    "        inputs, labels = data\n",
    "\n",
    "        if use_gpu:\n",
    "            inputs, labels = Variable(inputs.cuda(), requires_grad=True), Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs, labels = Variable(inputs, requires_grad=True), Variable(labels)\n",
    "\n",
    "        outputs = vgg(inputs)\n",
    "\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "#         loss = criterion(outputs, labels, smoothing=label_smoothing)\n",
    "        loss = criterion(outputs, labels)\n",
    "#         loss_test += loss.data[0]\n",
    "        loss_test += loss.item()\n",
    "\n",
    "        acc_test += torch.sum(preds == labels.data)\n",
    "\n",
    "        if use_gpu:\n",
    "            labels_pred = np.concatenate((labels_pred, preds.cpu()))\n",
    "            labels_expected = np.concatenate((labels_expected, labels.cpu()))\n",
    "        else:\n",
    "            labels_pred = np.concatenate((labels_pred, preds))\n",
    "            labels_expected = np.concatenate((labels_expected, labels))\n",
    "\n",
    "        del inputs, labels, outputs, preds\n",
    "        torch.cuda.empty_cache()\n",
    "    print(\"Expected label shape\",labels_expected.shape)    \n",
    "    print(\"Predicted label shape\",labels_pred.shape)    \n",
    "    avg_loss = loss_test / dataset_sizes[TEST]\n",
    "    avg_acc = acc_test / dataset_sizes[TEST]\n",
    "    \n",
    "    elapsed_time = time.time() - since\n",
    "    print(file = log)\n",
    "    print(\"Evaluation completed in {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60), file = log)\n",
    "    print(\"Avg loss (test): {:.4f}\".format(avg_loss), file = log)\n",
    "    print(\"Avg acc (test): {:.4f}\".format(avg_acc), file = log)\n",
    "    print('-' * 10, file = log)\n",
    "    \n",
    "    print(\"Confusion Matrix\", file=log)\n",
    "    print(confusion_matrix(labels_expected, labels_pred), file=log)  \n",
    "    print(\"-\"*30, file=log)\n",
    "#         print(\"Classification Report\")\n",
    "#         print(classification_report(y_label,out_predict))\n",
    "        \n",
    "    print(\"List of classification Accuracy\", file=log)\n",
    "    data = Counter(labels_expected[labels_expected==labels_pred])\n",
    "    stat = data.most_common()\n",
    "    stat = np.array(stat)\n",
    "    print(stat, file=log)   # Returns all unique items and their counts\n",
    "\n",
    "    print(\" The best classification accuracy is: \", \n",
    "          stat[0,1]/np.sum(labels_expected[labels_expected==stat[0,1]]), file=log)\n",
    "    print(\" The worst classification accuracy is: \", \n",
    "          stat[-1,1]/np.sum(labels_expected[labels_expected==stat[-1,1]]), file=log)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_cell_guid": "df23921b-f26e-496a-9a71-cdf2a9daa34e",
    "_uuid": "45d872d00fcfe93de8938b8741b4526af971c62b",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "HTJWo25nwhef"
   },
   "outputs": [],
   "source": [
    "lr_=0.05\n",
    "momentum_=0.9\n",
    "def set_up_network_param(net_type ='vgg16', freeze_training = False, clip_classifier = False, classification_size=10):\n",
    "    net = set_up_network(net_type, freeze_training = False, clip_classifier = False, classification_size=10)\n",
    "    if use_gpu:\n",
    "        net.cuda() #.cuda() will move everything to the GPU side\n",
    "#     criterion = cal_loss\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer_ft = optim.SGD(net.parameters(), lr=lr_, momentum=momentum_)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)\n",
    "    return net, criterion, optimizer_ft, exp_lr_scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file is common for both VGG and Alexnet\n",
    "\n",
    "data_dir_10 = \"/home/student/meowth/imgClas/food/class10\"  \n",
    "data_dir_30 = \"/home/student/meowth/imgClas/food/class30\"\n",
    "data_dir_100 = \"/home/student/meowth/imgClas/food/class100\"\n",
    "# data_dir_10 = \"C:\\DeepLearning\\images\\class10\"  \n",
    "# data_dir_30 = \"C:\\DeepLearning\\images\\class10\"\n",
    "# data_dir_100 = \"C:\\DeepLearning\\images\\class10\"\n",
    "ImageDirectory = [data_dir_10, data_dir_30, data_dir_100 ]\n",
    "\n",
    "TRAIN = 'train'\n",
    "TEST = 'test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning and evaluating VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete\n",
      "['beef_tartare', 'caesar_salad', 'chocolate_cake', 'croque_madame', 'escargots', 'fried_calamari', 'macaroni_and_cheese', 'poutine', 'spring_rolls', 'tuna_tartare']\n",
      "10\n",
      "----------\n",
      "Training batch 0/3750.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:96: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\n",
      "Training batch 0/3750.0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:60: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------\n",
      "\n",
      "Training batch 0/3750.0\n",
      "----------\n",
      "\n",
      "Training batch 0/3750.0\n",
      "----------\n",
      "\n",
      "Training batch 0/3750.0\n",
      "----------\n",
      "\n",
      "Evaluating model\n",
      "----------\n",
      "Expected label shape (50,)\n",
      "Predicted label shape (50,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Epochs = 10\n",
    "for i, data_dir in enumerate(ImageDirectory):\n",
    "    file = open(\"VGG16_Task2\"+str(i)+\".txt\", \"w\")\n",
    "    # Get Data\n",
    "    dataloaders, image_datasets = data_loader(file, data_dir, TRAIN, TEST, image_crop_size = 224, mini_batch_size = 10 )\n",
    "    dataset_sizes, classification_size, class_names = update_details(file, image_datasets)\n",
    "    \n",
    "    # Set up the network\n",
    "    vgg16, criterion, optimizer_ft, exp_lr_scheduler = set_up_network_param('vgg16', \n",
    "                         freeze_training = False, \n",
    "                         clip_classifier = False, \n",
    "                         classification_size=classification_size)\n",
    "\n",
    "    # training the model\n",
    "    vgg16 = train_model(file, vgg16, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, num_epochs=Epochs)\n",
    "    \n",
    "    # Testing the model\n",
    "    print(\"Testing the trained model\", file = file)\n",
    "    eval_model(file, vgg16, criterion)\n",
    "    \n",
    "    # Save the trained Model\n",
    "    torch.save(vgg16.state_dict(), \"VGG16_v1_task2_size_\"+str(classification_size)+\".pt\")\n",
    "    del vgg16, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, image_datasets\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading complete\n",
      "['beef_tartare', 'caesar_salad', 'chocolate_cake', 'croque_madame', 'escargots', 'fried_calamari', 'macaroni_and_cheese', 'poutine', 'spring_rolls', 'tuna_tartare']\n",
      "10\n",
      "Epoch 0/1----------\n",
      "Training batch 0/3750.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "\n",
      "Evaluating model\n",
      "----------\n",
      "Expected label shape (50,)\n",
      "Predicted label shape (50,)\n"
     ]
    }
   ],
   "source": [
    "Epochs = 10\n",
    "\n",
    "for i, data_dir in enumerate(ImageDirectory):\n",
    "    file = open(\"AlexNet_Task2\"+str(i)+\".txt\", \"w\")\n",
    "    # Get Data\n",
    "    dataloaders, image_datasets = data_loader(file, data_dir, TRAIN, TEST, image_crop_size = 224, mini_batch_size = 10 )\n",
    "    dataset_sizes, classification_size, class_names  = update_details(file, image_datasets)\n",
    "    \n",
    "    # Set up the network\n",
    "    alexnet, criterion, optimizer_ft, exp_lr_scheduler = set_up_network_param('alexnet', \n",
    "                         freeze_training = False, \n",
    "                         clip_classifier = False, \n",
    "                         classification_size=classification_size)\n",
    "\n",
    "    # training the model\n",
    "    alexnet = train_model(file, alexnet, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, num_epochs=Epochs)\n",
    "    \n",
    "    # Testing the model\n",
    "    print(\"Testing the trained model\", file = file)\n",
    "    eval_model(file, alexnet, criterion)\n",
    "    \n",
    "    # Save the trained Model\n",
    "    torch.save(alexnet.state_dict(), \"ALEXNET_v1_task2_size_\"+str(classification_size)+\".pt\")\n",
    "    del alexnet, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, image_datasets\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Using label smoothing regularisation\n",
    "The loss function is updated to include smoothing and is as shown here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 with label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs = 10\n",
    "\n",
    "# for i, data_dir in enumerate(ImageDirectory):\n",
    "#     file = open(\"VGG16_Task3\"+str(i)+\".txt\", \"w\")\n",
    "\n",
    "#     # Get Data\n",
    "#     dataloaders, image_datasets = data_loader(file, data_dir, TRAIN, TEST, image_crop_size = 224, mini_batch_size = 10 )\n",
    "#     dataset_sizes, classification_size = update_details(file, image_datasets)\n",
    "    \n",
    "#     # Set up the network\n",
    "#     vgg16, criterion, optimizer_ft, exp_lr_scheduler = set_up_network_param('vgg16', \n",
    "#                          freeze_training = False, \n",
    "#                          clip_classifier = False, \n",
    "#                          classification_size=classification_size)\n",
    "\n",
    "#     # training the model\n",
    "#     vgg16 = train_model(file, vgg16, \n",
    "#                         criterion, optimizer_ft, \n",
    "#                         exp_lr_scheduler, dataloaders,\n",
    "#                         num_epochs=Epochs, label_smoothing = True)\n",
    "    \n",
    "#     # Testing the model\n",
    "#     print(\"Testing the trained model\", file = file)\n",
    "#     eval_model(file, vgg16, criterion, label_smoothing = True)\n",
    "    \n",
    "#     # Save the trained Model\n",
    "#     torch.save(vgg16.state_dict(), \"VGG16_v1_task3_size_\"+str(classification_size)+\".pt\")\n",
    "#     del vgg16, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, image_datasets\n",
    "#     file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AlexNet with label smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Epochs = 10\n",
    "\n",
    "# for i, data_dir in enumerate(ImageDirectory):\n",
    "#     file = open(\"AlexNet_Task3\"+str(i)+\".txt\", \"w\")\n",
    "#     # Get Data\n",
    "#     dataloaders, image_datasets = data_loader(file, data_dir, TRAIN, TEST, image_crop_size = 224, mini_batch_size = 10 )\n",
    "#     dataset_sizes, classification_size = update_details(file, image_datasets)\n",
    "    \n",
    "#     # Set up the network\n",
    "#     alexnet, criterion, optimizer_ft, exp_lr_scheduler = set_up_network_param('alexnet', \n",
    "#                          freeze_training = False, \n",
    "#                          clip_classifier = False, \n",
    "#                          classification_size=classification_size)\n",
    "\n",
    "#     # training the model\n",
    "#     alexnet = train_model(file, alexnet, criterion, \n",
    "#                           optimizer_ft, exp_lr_scheduler,\n",
    "#                           dataloaders, num_epochs=Epochs,\n",
    "#                          label_smoothing = True)\n",
    "    \n",
    "#     # Testing the model\n",
    "#     print(\"Testing the trained model\", file = file)\n",
    "#     eval_model(file, alexnet, criterion, label_smoothing = True)\n",
    "    \n",
    "#     # Save the trained Model\n",
    "#     torch.save(alexnet.state_dict(), \"ALEXNET_v1_task3_size_\"+str(classification_size)+\".pt\")\n",
    "#     del alexnet, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, image_datasets\n",
    "#     file.close()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "VGG16_v2-OCT2017_Retina.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
